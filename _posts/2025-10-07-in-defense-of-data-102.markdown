---
layout: post
title:  "In Defense of Data 102"
subtitle: "A very enlightening class with a seemingly unclear thesis"
date:   2025-10-07 00:00:00 -0500
categories: jekyll update
---

**Table of contents:**
[So What is Data 102?](#so-what-is-data-102) | [So What is Data 102 About?](#so-what-is-data-102-about) | [So What's the Problem?](#so-whats-the-problem)


## So What is Data 102?

This is going to be a very Berkeley-centric article. If I have any readers who did not go to Berkeley (which is really only Chris – hi, Chris!), then this is probably going to be a very confusing article.

But for some brief background, the data science major at Berkeley has certain <a href="https://cdss.berkeley.edu/dsus/academics/majorrequirements#section-el--3">upper division requirements to complete the major</a> (like literally any other major does), and one of those requirements is a modeling requirement ("MLDM"). Data science majors have some leeway on what class they can take: some opt for the notoriously challenging machine learning class <a href="https://people.eecs.berkeley.edu/~jrs/189s24/">CS 189</a>, some opt for its never-talked-about equivalent in the statistics department <a href="https://stat154.berkeley.edu/">STAT 154</a>, and a smaller bunch opt for the machine learning class that people take to pad their GPA because they're scared of math, <a href="https://classes.berkeley.edu/content/2025-spring-indeng-142a-1-lec-1">IND ENG 142A</a>.

But outside of machine learning, there's also the class that's actually offered by the Data Science Department itself to satisfy its own major requirements: <a href="https://data102.org/fa24/">Data 102</a>, officially titled "Data, Inference, and Decisions." What does that mean? Well, if you ask the average data science major, they either don't know what the class is exactly about, or they'll say something along the lines of, "It was kind of all over the place, we talked about really random things every week that didn't really relate to each other like classification, linear models, causal inference, and some machine learning stuff."

Honestly, that's not even an incorrect description of the class content, but I think it misses what the class is actually about. And I really like what the class is about, which is half of what compelled me to write this blogpost.

The other half of what compelled me to write this blogpost is that I saw that Data 102 will not be offered next semester, and per the announcement, the Data Science Department is "expect[ing] to add an MLDM course offered by Data Science to the Schedule of Classes" that, according to my read, is a new, different class from Data 102.[^1]

I don't hate this idea, and I've long believed the data science major should expand the coursework options under its own departmental name. But I really hope this class does not permanently *replace* Data 102, because I'm quite a fan of the class and think it's just heavily misunderstood.

## So What is Data 102 About?

Consider the audience of Data 102: mostly mature juniors and seniors who have already taken an advanced probability course and are about a year away from becoming working data scientists in the real-world. As such, the class' purpose is to try and teach these students what "data science" actually is at a more advanced, abstract level. In short, it's trying to be a microcosm of "data science," and trying to cover all sorts of "modeling" frameworks under this umbrella.

But in doing so, Data 102 actually takes a very simple, elegant thesis of what "data science" actually means – and it's one that's literally in the title of the course. Data science is about *decision-making*. And when you make decisions, you have to confront certain *tradeoffs*.

I'm a huge fan of this philosophy, especially in the context of a modeling class. Too often, the actual human element of constructing a model is either usually completely abstracted away from students, because we're so used to just churning out copy-pasted pandas and scikit-learn code that we fail to realize that every single minute decision we make in that process – from whether we choose to drop or impute missing data to the metric we're trying to optimize for – comes with certain costs, and different intermediate decisions can lead to entirely different results.

Data 102 actually confronts this head-on! I remember reading a really good <a href="https://www.pnas.org/doi/10.1073/pnas.2203150119">research paper</a> they presented in class, where hundreds of researchers across over 70 independent research teams were asked to analyze the same hypothesis with the same dataset, and even working in good-faith, they all came to surprisingly different conclusions: "Little more than half the reported estimates were statistically not significantly different from zero at 95% CI, while a quarter were significantly different and negative, and 16.9% were statistically significant and positive."[^2]

As data scientists, we make so many unique, individual decisions when we analyze data, from our strategies on how to handle missing data to which features we include or exclude, and this paper raises the salience of debating the underlying *assumptions* of those decisions rather than the results themselves necessarily. As the paper states, ""Researchers must make analytical decisions so minute that they often do not even register as decisions. Instead, they go unnoticed as nondeliberate actions following ostensibly standard operating procedures."

The purpose of Data 102, then, is to introduce various modeling constructs across data science, and show that the thing they all have in common is they involve certain *human* decision-making processes, and each one of those decisions has a tradeoff.

1. When we learned about classification, we were taught about the <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity">tradeoff between sensitivity and specificity.</a> For example, if you have a classifier where you predict whether someone has a disease like cancer, there is a tradeoff between making a false positive and false negative. You can be extremely conservative at diagnosing someone with cancer, at the cost of failing to correctly diagnose someone who does have cancer; and conversely, you can be much more generous with your classifications to ensure you do not misdiagnose someone who has cancer, at the cost of potentially sending a perfectly health individual to chemotherapy.
2. We learned about frequentist and Bayesian paradigms of statistics. Sure, the more obvious, surface-level lesson is "there are different schools of thought in statistical inference," but the actual lesson here also has to do with decision-making and tradeoffs. Bayesian modeling is really focused on constructing a good prior, because the inferences you make about the parameters you are trying to estimate vary based on how strong your prior is. That's an entirely human modeling choice, and a good prior requires some sort of scientific (or at the very least probabilistic) justification. Similarly, frequentist statistics does have asymptotic guarantees on the parameters you estimate conditional on the data, but your data is also random, meaning that even with a 95% confidence interval, you are still resigning yourself to making a false positive (i.e., incorrectly rejecting a correct null hypothesis [see also: <a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>]) 5% of the time. But there are ways to be more <a href="https://en.wikipedia.org/wiki/Bonferroni_correction">conservative</a> so you make <a href="https://en.wikipedia.org/wiki/False_discovery_rate">fewer false discoveries</a>! That's still a decision with a tradeoff, but each paradigm has its own set of tradeoffs – and that's the point!
3. We have a one month unit on GLMs, machine learning, and causal inference, which seem totally random and out of place when they are presented in class. Like sure, they're all "models" and have statistical underpinnings, but how does it relate to decision making? Again, it's about *tradeoffs*, and the main lesson of talking about these models is the tradeoff between accuracy and interpretability.[^3] Simpler models like regression models/GLMs and lone decision trees are still helpful because they allow us to very easily interpret how our model inputs influence our outputs – and in fact, there's a whole causal inference toolkit we can use to make actual, causal statements about our observations – at the cost of potentially underfitting to the data and being less accurate. More complex, non-linear functions like random forests or neural networks trade some of that interpretability for more accuracy. (Related though not exactly what I'm talking about here: <a href="https://mlu-explain.github.io/bias-variance/">bias-variance tradeoff</a>, which in short is about the tradeoff between model complexity and generalizability).
4. We spent the last month on seemingly weird "special topics," like reinforcement learning and differential privacy. Even still, these all follow the same fundamental thesis of the class: these are all decision-making problems, and decisions have tradeoffs! Reinforcement learning of course has the <a href="https://en.wikipedia.org/wiki/Exploration%E2%80%93exploitation_dilemma">exploration-exploitation tradeoff</a>, which we saw through the lens of multi-armed bandit problems, and differential privacy represents a tradeoff between privacy and utility (i.e., how much can you obfuscate data to maintain privacy of the individuals in the data while still making correct inferences from the data).

So once you reframe how you think about the class – it's a class about decision-making, and the tradeoffs those decisions represent – the class actually has what I think are really profound takeaways, and definitely did a lot to inspire me to explore a lot of the topics further,[^4] both while I was still at Berkeley and in grad school through my coursework and research.

## So What's the Problem?

When I said Data 102 is meant to be a microcosm of data science, I mean that in both good and bad ways. The data science major at Berkeley – and honestly, the field of data science at large – struggles with wanting to be an "everything bagel" field; in other words, they want to be too many things at once at the cost of not being sufficiently deep in any of those things. Berkeley's data science major is *supposed* to be the perfect blend of statistics and computer science, but its students end up not having depth in either statistics or computer science. Data 102 similarly suffers from this "everything bagel" problem.

Fundamentally, the class is a survey class, meaning it's not really designed to go in-depth onto any one topic. I think that's where the main problem of the class lies and why it ends up feeling like a hodgepodge of totally detached topics for most of the students who take it. And even though I really like the unifying theme and philosophy of the class, "data science as decision making," I will also be the first to agree that you don't really gain much technical depth in any of the topics covered by taking the class.

For me, this wasn't that big a deal, because I took Data 102 after I'd already taken essentially every individual modeling class that Data 102 touches on. I'd taken causal inference a year before (in fact, I was the TA for causal inference when I took Data 102); I took CS 189 the semester before, so the machine learning was all entirely review; and I'd taken Berkeley's graduate linear models course Stat 230A the semester before, so the entire unit on GLMs was completely review.

Given the background I came in with, I think that's why I was more able to appreciate the underlying philosophy of the course while not compromising on my own learning – and why I felt the class was ultimately more enriching than a waste of time (plus, Alexander Strang and Ramesh Sridharan were beyond fantastic lecturers, two of the best I ever had at Berkeley.)

But again, if there were a data science major at Berkeley who took all the departmental courses and graduated having only taken Data 102 and no other modeling class, I would confidently tell you this person did not take a proper machine learning class in the same way someone who took CS 189 – or hell, even IND ENG 142A – did. Part of the irony here is that the decision to take Data 102 has its own tradeoff – you get to explore a lot of really interesting subfields of statistics and machine learning through a really rich philosophy, at the cost of not really gaining any mastery over any of those subfields.

(**Edit 10/11/2025**: After thinking about this some more, I'll go as far as saying that I'm perfectly fine if Data 102 is scrapped from satisfying the MLDM requirement, because of its insufficient technical depth. However, I don't think the purpose of the class is to be technically deep, and it's still valuable as a "junior seminar" course regardless of whether it satisfies the modeling requirement. As such, I hope it doesn't get permanently axed.)

So why am I writing "in defense of Data 102" given the all these problems? It's because I don't think it's the fault of Data 102 that it's designed to be a survey course. Not every class needs to be a gnarly technical deep-dive on one topic; if you want to take those classes, you have my blessing and I encourage you to do so. But some classes are meant to be more "inspirational" or "exploratory" or at least get you think, and I think Data 102 does exactly that. Perhaps I'm biased because I came in having done most of the "technical deep dives" covered in Data 102 in my prior coursework, but I think the correct structure for other students would be to take Data 102 at least a semester before you graduate, and then sign up for classes that go deeper on things you found interesting in 102 – like causal inference or deep learning or linear models or whatever else.[^5] (Also worth considering: a lot of the people who sign up for Data 102 do not really care about the course and have it as one of the last required classes to graduate senior year, so they're really in a "just put the fries in the bag bro" situation and probably don't give a shit whether they are enriched by future coursework or not. But those people are not the target audience of this post :D)

Even though it's not a perfect class, I hope the decision to axe Data 102 from the course schedule isn't a permanent one. I don't think any other statistics upper division class even *touches* Bayesian statistics until the graduate level (save for that one week in Stat 135 where it was the last unit), and causal inference is offered only one semester per year. There are some really valuable lessons to be gleaned from Data 102, so if it's not coming back again, I hope its replacement(s) can sufficiently teach the important lessons I learned so much from when I took the class.

---
#### Footnotes
[^1]: <small>I don't know why I care, considering I already graduated from Berkeley with my data science degree.</small>
[^2]: <small>Kind of a side tangent here: <a href="https://academic.oup.com/ej/article-abstract/134/662/2439/7659819?redirectedFrom=fulltext&login=false">a paper came out a few months ago</a> that used gradient-boosted trees to predict partisanship among economic researchers, and found that an economist's political leanings do influence their published estimates of things like "optimal tax rates" for the highest income earners, with the most left-leaning economist suggesting an optimal tax rate of 77% while the most right-leaning economist suggested an optimal tax rate of 60%. Breznau's study was majority sociologists and political scientists, in addition to economists, but it is interesting to see empirical evidence that partisanship does actually influence a paper's results independent of just "good faith attempts to analyze data." I don't think this necessarily conflicts with the findings of the Breznau paper – which mainly showed that even starting with the same data/set of observations, researchers can come to different results largely as a product of varying minute decisions – but the studies in this paper may all have had different data sources to begin with which may themselves have been chosen as a result of something like partisanship. (Even then, some economists have celebrated the findings as a win, suggesting that even with a partisan effect the results on each end of the spectrum don't disagree that much!)</small>
[^3]: <small>I had an interview where I was asked about this recently, so if you want to get super technical and annoying about it, you can still interpret opaque models like random forests or even neural networks through things like <a href="https://scikit-learn.org/stable/modules/permutation_importance.html"> permutation feature importance </a> or <a href="https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html">SHAP values</a>.</small>
[^4]: <small>I wrote a subfield survey the semester after on the intersection of NLP and multi-armed bandits, which I was inspired to learn more about after taking 102! I also signed up for a graduate Bayesian statistics class (but unfortunately ended up dropping it after a week because I decided I wanted to go to Taco Tuesday every week instead of studying for our weekly quiz).</small>
[^5]: <small>The complicating factor here is there's just not much *time* to take all these courses given most people take the probability prerequisite for Data 102 really late to begin with, meaning most people only take Data 102 in their last three semesters at Berkeley (and some of those people take it in their very last semester!). I actually think the solution here is to add a required lower division probability and discrete math course similar to CS 70 for data science, since (1) the probability required for Data 102 is relatively lightweight anyway ... you definitely do NOT need all the probability from Data 140 to understand Data 102, (2) it's probably just beneficial overall if data science students have a dedicated class to developing their mathematical maturity before Data 140, and (3) I think the correct role of Data 102 should be a survey class you can take your sophomore year or your junior fall so you have ample time to explore the topics after taking the class; I don't think there's any reason why you can't take Data 102 and Data 140 at the same time.</small>